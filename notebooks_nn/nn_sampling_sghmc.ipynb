{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from neural_net.mlp import MLP\n",
    "from neural_net.nn_utils import compute_jacobian\n",
    "from models.hd_regression_model import HDRegressionModel\n",
    "from models.ld_regression_model import LDRegressionModel\n",
    "from sampling.least_squares_sampler import LeastSquaresSampler\n",
    "from sampling.sghmc_sampling import SGHMCsampler\n",
    "from sampling.rate_schedulers import *\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models.model_generators import *\n",
    "from sampling.rate_schedulers import *\n",
    "from neural_net.nn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Training Network\n",
      "Epoch 0, Loss: 0.9714, Validation Loss: 3870.7981\n",
      "Epoch 100, Loss: 0.8509, Validation Loss: 3387.1194\n",
      "Epoch 200, Loss: 0.7614, Validation Loss: 2956.7720\n",
      "Epoch 300, Loss: 0.6702, Validation Loss: 2601.6462\n",
      "Epoch 400, Loss: 0.6054, Validation Loss: 2321.8655\n",
      "Epoch 500, Loss: 0.5611, Validation Loss: 2109.4800\n",
      "Epoch 600, Loss: 0.5244, Validation Loss: 1954.2017\n",
      "Epoch 700, Loss: 0.4988, Validation Loss: 1843.7627\n",
      "Epoch 800, Loss: 0.4775, Validation Loss: 1765.3984\n",
      "Epoch 900, Loss: 0.4651, Validation Loss: 1707.8715\n",
      "Epoch 1000, Loss: 0.4607, Validation Loss: 1663.5486\n",
      "Epoch 1100, Loss: 0.4418, Validation Loss: 1625.6606\n",
      "Epoch 1200, Loss: 0.4372, Validation Loss: 1593.6300\n",
      "Epoch 1300, Loss: 0.4282, Validation Loss: 1565.1472\n",
      "Epoch 1400, Loss: 0.4238, Validation Loss: 1538.8008\n",
      "Epoch 1500, Loss: 0.4120, Validation Loss: 1514.9304\n",
      "Epoch 1600, Loss: 0.4126, Validation Loss: 1492.8330\n",
      "Epoch 1700, Loss: 0.4026, Validation Loss: 1472.6213\n",
      "Epoch 1800, Loss: 0.3982, Validation Loss: 1453.5938\n",
      "Epoch 1900, Loss: 0.3976, Validation Loss: 1435.8409\n",
      "Epoch 2000, Loss: 0.3874, Validation Loss: 1419.0886\n",
      "Epoch 2100, Loss: 0.3831, Validation Loss: 1403.1309\n",
      "Epoch 2200, Loss: 0.3779, Validation Loss: 1388.4041\n",
      "Epoch 2300, Loss: 0.3741, Validation Loss: 1374.6169\n",
      "Epoch 2400, Loss: 0.3730, Validation Loss: 1361.1903\n",
      "Epoch 2500, Loss: 0.3693, Validation Loss: 1348.5638\n",
      "Epoch 2600, Loss: 0.3682, Validation Loss: 1336.6096\n",
      "Epoch 2700, Loss: 0.3640, Validation Loss: 1325.4502\n",
      "Epoch 2800, Loss: 0.3663, Validation Loss: 1315.1797\n",
      "Epoch 2900, Loss: 0.3572, Validation Loss: 1305.4761\n",
      "Epoch 3000, Loss: 0.3552, Validation Loss: 1296.0887\n",
      "Epoch 3100, Loss: 0.3540, Validation Loss: 1287.2578\n",
      "Epoch 3200, Loss: 0.3535, Validation Loss: 1278.9352\n",
      "Epoch 3300, Loss: 0.3498, Validation Loss: 1270.6290\n",
      "Epoch 3400, Loss: 0.3445, Validation Loss: 1262.9486\n",
      "Epoch 3500, Loss: 0.3442, Validation Loss: 1255.5931\n",
      "Epoch 3600, Loss: 0.3431, Validation Loss: 1248.4860\n",
      "Epoch 3700, Loss: 0.3409, Validation Loss: 1242.1664\n",
      "Epoch 3800, Loss: 0.3437, Validation Loss: 1235.4364\n",
      "Epoch 3900, Loss: 0.3396, Validation Loss: 1229.1731\n",
      "Epoch 4000, Loss: 0.3380, Validation Loss: 1223.1604\n",
      "Epoch 4100, Loss: 0.3341, Validation Loss: 1217.3320\n",
      "Epoch 4200, Loss: 0.3348, Validation Loss: 1211.4419\n",
      "Epoch 4300, Loss: 0.3310, Validation Loss: 1205.8829\n",
      "Epoch 4400, Loss: 0.3295, Validation Loss: 1200.1130\n",
      "Epoch 4500, Loss: 0.3242, Validation Loss: 1194.9845\n",
      "Epoch 4600, Loss: 0.3228, Validation Loss: 1189.4458\n",
      "Epoch 4700, Loss: 0.3262, Validation Loss: 1184.2656\n",
      "Epoch 4800, Loss: 0.3198, Validation Loss: 1179.0962\n",
      "Epoch 4900, Loss: 0.3177, Validation Loss: 1174.1320\n",
      "Epoch 5000, Loss: 0.3204, Validation Loss: 1169.0144\n",
      "Epoch 5100, Loss: 0.3183, Validation Loss: 1164.2194\n",
      "Epoch 5200, Loss: 0.3170, Validation Loss: 1159.4874\n",
      "Epoch 5300, Loss: 0.3140, Validation Loss: 1154.7523\n",
      "Epoch 5400, Loss: 0.3133, Validation Loss: 1149.8041\n",
      "Epoch 5500, Loss: 0.3180, Validation Loss: 1144.9872\n",
      "Epoch 5600, Loss: 0.3076, Validation Loss: 1139.9919\n",
      "Epoch 5700, Loss: 0.3092, Validation Loss: 1134.0260\n",
      "Epoch 5800, Loss: 0.3084, Validation Loss: 1128.5841\n",
      "Epoch 5900, Loss: 0.3063, Validation Loss: 1123.6536\n",
      "Epoch 6000, Loss: 0.3071, Validation Loss: 1118.9551\n",
      "Epoch 6100, Loss: 0.3025, Validation Loss: 1114.2550\n",
      "Epoch 6200, Loss: 0.3035, Validation Loss: 1109.8763\n",
      "Epoch 6300, Loss: 0.2995, Validation Loss: 1105.3511\n",
      "Epoch 6400, Loss: 0.3032, Validation Loss: 1101.8353\n",
      "Epoch 6500, Loss: 0.2985, Validation Loss: 1098.0798\n",
      "Epoch 6600, Loss: 0.2991, Validation Loss: 1094.0481\n",
      "Epoch 6700, Loss: 0.2953, Validation Loss: 1090.5964\n",
      "Epoch 6800, Loss: 0.2960, Validation Loss: 1087.0203\n",
      "Epoch 6900, Loss: 0.2955, Validation Loss: 1083.1942\n",
      "Epoch 7000, Loss: 0.2953, Validation Loss: 1080.1835\n",
      "Epoch 7100, Loss: 0.2944, Validation Loss: 1076.8309\n",
      "Epoch 7200, Loss: 0.2938, Validation Loss: 1073.5934\n",
      "Epoch 7300, Loss: 0.2906, Validation Loss: 1070.7736\n",
      "Epoch 7400, Loss: 0.2920, Validation Loss: 1067.8035\n",
      "Epoch 7500, Loss: 0.2932, Validation Loss: 1064.9972\n",
      "Epoch 7600, Loss: 0.2888, Validation Loss: 1062.4517\n",
      "Epoch 7700, Loss: 0.2869, Validation Loss: 1059.7662\n",
      "Epoch 7800, Loss: 0.2901, Validation Loss: 1056.8905\n",
      "Epoch 7900, Loss: 0.2907, Validation Loss: 1054.8414\n",
      "Epoch 8000, Loss: 0.2863, Validation Loss: 1052.1448\n",
      "Epoch 8100, Loss: 0.2852, Validation Loss: 1050.1672\n",
      "Epoch 8200, Loss: 0.2891, Validation Loss: 1047.8741\n",
      "Epoch 8300, Loss: 0.2832, Validation Loss: 1045.6973\n",
      "Epoch 8400, Loss: 0.2834, Validation Loss: 1043.9316\n",
      "Epoch 8500, Loss: 0.2815, Validation Loss: 1041.9191\n",
      "Epoch 8600, Loss: 0.2784, Validation Loss: 1039.7585\n",
      "Epoch 8700, Loss: 0.2837, Validation Loss: 1037.9685\n",
      "Epoch 8800, Loss: 0.2807, Validation Loss: 1036.6619\n",
      "Epoch 8900, Loss: 0.2803, Validation Loss: 1034.6230\n",
      "Epoch 9000, Loss: 0.2797, Validation Loss: 1032.8477\n",
      "Epoch 9100, Loss: 0.2791, Validation Loss: 1031.3226\n",
      "Epoch 9200, Loss: 0.2805, Validation Loss: 1029.4609\n",
      "Epoch 9300, Loss: 0.2798, Validation Loss: 1027.6874\n",
      "Epoch 9400, Loss: 0.2788, Validation Loss: 1025.9832\n",
      "Epoch 9500, Loss: 0.2770, Validation Loss: 1024.4528\n",
      "Epoch 9600, Loss: 0.2772, Validation Loss: 1022.5348\n",
      "Epoch 9700, Loss: 0.2752, Validation Loss: 1021.4130\n",
      "Epoch 9800, Loss: 0.2736, Validation Loss: 1019.7170\n",
      "Epoch 9900, Loss: 0.2742, Validation Loss: 1018.0058\n",
      "Epoch 10000, Loss: 0.2731, Validation Loss: 1016.2048\n",
      "Epoch 10100, Loss: 0.2741, Validation Loss: 1014.2886\n",
      "Epoch 10200, Loss: 0.2768, Validation Loss: 1012.3015\n",
      "Epoch 10300, Loss: 0.2745, Validation Loss: 1011.0479\n",
      "Epoch 10400, Loss: 0.2752, Validation Loss: 1009.6608\n",
      "Epoch 10500, Loss: 0.2720, Validation Loss: 1008.4005\n",
      "Epoch 10600, Loss: 0.2679, Validation Loss: 1006.8711\n",
      "Epoch 10700, Loss: 0.2746, Validation Loss: 1005.3958\n",
      "Epoch 10800, Loss: 0.2715, Validation Loss: 1004.3711\n",
      "Epoch 10900, Loss: 0.2709, Validation Loss: 1003.2160\n",
      "Epoch 11000, Loss: 0.2722, Validation Loss: 1002.6728\n",
      "Epoch 11100, Loss: 0.2681, Validation Loss: 1001.7181\n",
      "Epoch 11200, Loss: 0.2701, Validation Loss: 1001.1337\n",
      "Epoch 11300, Loss: 0.2687, Validation Loss: 1000.4540\n",
      "Epoch 11400, Loss: 0.2719, Validation Loss: 999.6534\n",
      "Epoch 11500, Loss: 0.2720, Validation Loss: 999.5142\n",
      "Epoch 11600, Loss: 0.2712, Validation Loss: 999.0702\n",
      "Epoch 11700, Loss: 0.2704, Validation Loss: 998.5140\n",
      "Epoch 11800, Loss: 0.2686, Validation Loss: 998.3271\n",
      "Epoch 11900, Loss: 0.2664, Validation Loss: 997.4986\n",
      "Epoch 12000, Loss: 0.2707, Validation Loss: 997.1061\n",
      "Epoch 12100, Loss: 0.2688, Validation Loss: 997.1438\n",
      "Epoch 12200, Loss: 0.2676, Validation Loss: 996.4050\n",
      "Epoch 12300, Loss: 0.2687, Validation Loss: 996.2620\n",
      "Epoch 12400, Loss: 0.2720, Validation Loss: 996.1946\n",
      "Epoch 12500, Loss: 0.2656, Validation Loss: 995.9662\n",
      "Epoch 12600, Loss: 0.2686, Validation Loss: 995.9404\n",
      "Epoch 12700, Loss: 0.2711, Validation Loss: 995.3989\n",
      "Epoch 12800, Loss: 0.2699, Validation Loss: 995.4453\n",
      "Epoch 12900, Loss: 0.2703, Validation Loss: 994.9405\n",
      "Epoch 13000, Loss: 0.2668, Validation Loss: 994.6912\n",
      "Epoch 13100, Loss: 0.2692, Validation Loss: 994.4084\n",
      "Epoch 13200, Loss: 0.2649, Validation Loss: 994.4949\n",
      "Epoch 13300, Loss: 0.2673, Validation Loss: 994.3780\n",
      "Epoch 13400, Loss: 0.2661, Validation Loss: 994.1824\n",
      "Epoch 13500, Loss: 0.2670, Validation Loss: 994.0933\n",
      "Epoch 13600, Loss: 0.2635, Validation Loss: 993.7728\n",
      "Epoch 13700, Loss: 0.2656, Validation Loss: 993.3159\n",
      "Epoch 13800, Loss: 0.2674, Validation Loss: 993.5419\n",
      "Epoch 13900, Loss: 0.2709, Validation Loss: 993.2888\n",
      "Epoch 14000, Loss: 0.2674, Validation Loss: 992.9298\n",
      "Epoch 14100, Loss: 0.2684, Validation Loss: 992.8033\n",
      "Epoch 14200, Loss: 0.2672, Validation Loss: 992.6837\n",
      "Epoch 14300, Loss: 0.2652, Validation Loss: 992.4865\n",
      "Epoch 14400, Loss: 0.2660, Validation Loss: 991.9523\n",
      "Epoch 14500, Loss: 0.2657, Validation Loss: 991.8489\n",
      "Epoch 14600, Loss: 0.2672, Validation Loss: 991.7980\n",
      "Epoch 14700, Loss: 0.2681, Validation Loss: 991.7490\n",
      "Epoch 14800, Loss: 0.2659, Validation Loss: 991.8023\n",
      "Epoch 14900, Loss: 0.2681, Validation Loss: 991.4706\n",
      "Epoch 15000, Loss: 0.2651, Validation Loss: 991.5101\n",
      "Epoch 15100, Loss: 0.2676, Validation Loss: 991.2857\n",
      "Epoch 15200, Loss: 0.2669, Validation Loss: 991.2877\n",
      "Epoch 15300, Loss: 0.2660, Validation Loss: 991.5074\n",
      "Epoch 15400, Loss: 0.2643, Validation Loss: 991.2966\n",
      "Epoch 15500, Loss: 0.2673, Validation Loss: 991.0113\n",
      "Epoch 15600, Loss: 0.2674, Validation Loss: 990.8574\n",
      "Epoch 15700, Loss: 0.2642, Validation Loss: 991.0138\n",
      "Epoch 15800, Loss: 0.2668, Validation Loss: 990.8642\n",
      "Epoch 15900, Loss: 0.2642, Validation Loss: 990.4764\n",
      "Epoch 16000, Loss: 0.2655, Validation Loss: 990.8171\n",
      "Epoch 16100, Loss: 0.2649, Validation Loss: 990.6770\n",
      "Epoch 16200, Loss: 0.2635, Validation Loss: 990.2477\n",
      "Epoch 16300, Loss: 0.2673, Validation Loss: 990.4818\n",
      "Epoch 16400, Loss: 0.2676, Validation Loss: 990.4368\n",
      "Epoch 16500, Loss: 0.2664, Validation Loss: 990.2263\n",
      "Epoch 16600, Loss: 0.2663, Validation Loss: 990.0236\n",
      "Epoch 16700, Loss: 0.2650, Validation Loss: 989.9565\n",
      "Epoch 16800, Loss: 0.2648, Validation Loss: 990.1605\n",
      "Epoch 16900, Loss: 0.2667, Validation Loss: 989.9418\n",
      "Epoch 17000, Loss: 0.2665, Validation Loss: 989.6248\n",
      "Epoch 17100, Loss: 0.2653, Validation Loss: 989.9844\n",
      "Epoch 17200, Loss: 0.2685, Validation Loss: 990.0588\n",
      "Epoch 17300, Loss: 0.2668, Validation Loss: 989.9392\n",
      "Epoch 17400, Loss: 0.2653, Validation Loss: 989.8448\n",
      "Epoch 17500, Loss: 0.2665, Validation Loss: 989.4387\n",
      "Epoch 17600, Loss: 0.2633, Validation Loss: 989.6290\n",
      "Epoch 17700, Loss: 0.2661, Validation Loss: 989.3518\n",
      "Epoch 17800, Loss: 0.2665, Validation Loss: 989.2754\n",
      "Epoch 17900, Loss: 0.2651, Validation Loss: 989.5487\n",
      "Epoch 18000, Loss: 0.2618, Validation Loss: 989.3062\n",
      "Epoch 18100, Loss: 0.2648, Validation Loss: 989.0646\n",
      "Epoch 18200, Loss: 0.2658, Validation Loss: 989.1814\n",
      "Epoch 18300, Loss: 0.2670, Validation Loss: 988.9213\n",
      "Epoch 18400, Loss: 0.2655, Validation Loss: 989.0538\n",
      "Epoch 18500, Loss: 0.2627, Validation Loss: 988.9565\n",
      "Epoch 18600, Loss: 0.2640, Validation Loss: 988.8616\n",
      "Epoch 18700, Loss: 0.2650, Validation Loss: 988.9409\n",
      "Epoch 18800, Loss: 0.2662, Validation Loss: 989.1359\n",
      "Epoch 18900, Loss: 0.2662, Validation Loss: 989.4567\n",
      "Epoch 19000, Loss: 0.2633, Validation Loss: 989.2897\n",
      "Epoch 19100, Loss: 0.2681, Validation Loss: 989.1295\n",
      "Epoch 19200, Loss: 0.2637, Validation Loss: 989.0516\n",
      "Epoch 19300, Loss: 0.2656, Validation Loss: 989.0970\n",
      "Epoch 19400, Loss: 0.2649, Validation Loss: 988.4913\n",
      "Epoch 19500, Loss: 0.2659, Validation Loss: 988.0756\n",
      "Epoch 19600, Loss: 0.2626, Validation Loss: 988.4204\n",
      "Epoch 19700, Loss: 0.2634, Validation Loss: 988.2488\n",
      "Epoch 19800, Loss: 0.2671, Validation Loss: 987.9651\n",
      "Epoch 19900, Loss: 0.2654, Validation Loss: 987.8840\n",
      "Epoch 20000, Loss: 0.2656, Validation Loss: 987.7360\n",
      "Epoch 20100, Loss: 0.2650, Validation Loss: 987.5367\n",
      "Epoch 20200, Loss: 0.2640, Validation Loss: 987.4374\n",
      "Epoch 20300, Loss: 0.2635, Validation Loss: 987.2934\n",
      "Epoch 20400, Loss: 0.2633, Validation Loss: 987.3045\n",
      "Epoch 20500, Loss: 0.2647, Validation Loss: 987.2265\n",
      "Epoch 20600, Loss: 0.2673, Validation Loss: 986.7672\n",
      "Epoch 20700, Loss: 0.2643, Validation Loss: 986.7292\n",
      "Epoch 20800, Loss: 0.2641, Validation Loss: 986.9357\n",
      "Epoch 20900, Loss: 0.2647, Validation Loss: 986.8857\n",
      "Epoch 21000, Loss: 0.2662, Validation Loss: 986.5444\n",
      "Epoch 21100, Loss: 0.2673, Validation Loss: 986.8268\n",
      "Epoch 21200, Loss: 0.2630, Validation Loss: 986.5833\n",
      "Epoch 21300, Loss: 0.2644, Validation Loss: 986.4599\n",
      "Epoch 21400, Loss: 0.2637, Validation Loss: 986.1229\n",
      "Epoch 21500, Loss: 0.2631, Validation Loss: 985.9360\n",
      "Epoch 21600, Loss: 0.2648, Validation Loss: 985.4177\n",
      "Epoch 21700, Loss: 0.2654, Validation Loss: 985.3770\n",
      "Epoch 21800, Loss: 0.2649, Validation Loss: 985.5566\n",
      "Epoch 21900, Loss: 0.2664, Validation Loss: 985.5170\n",
      "Epoch 22000, Loss: 0.2656, Validation Loss: 985.0029\n",
      "Epoch 22100, Loss: 0.2655, Validation Loss: 984.6160\n",
      "Epoch 22200, Loss: 0.2632, Validation Loss: 984.6390\n",
      "Epoch 22300, Loss: 0.2649, Validation Loss: 984.6780\n",
      "Epoch 22400, Loss: 0.2652, Validation Loss: 984.4701\n",
      "Epoch 22500, Loss: 0.2629, Validation Loss: 984.5898\n",
      "Epoch 22600, Loss: 0.2612, Validation Loss: 984.1775\n",
      "Epoch 22700, Loss: 0.2680, Validation Loss: 983.9386\n",
      "Epoch 22800, Loss: 0.2633, Validation Loss: 983.5885\n",
      "Epoch 22900, Loss: 0.2645, Validation Loss: 983.3615\n",
      "Epoch 23000, Loss: 0.2633, Validation Loss: 982.3638\n",
      "Epoch 23100, Loss: 0.2625, Validation Loss: 982.4137\n",
      "Epoch 23200, Loss: 0.2647, Validation Loss: 982.6431\n",
      "Epoch 23300, Loss: 0.2649, Validation Loss: 982.4061\n",
      "Epoch 23400, Loss: 0.2656, Validation Loss: 982.2009\n",
      "Epoch 23500, Loss: 0.2656, Validation Loss: 982.1909\n",
      "Epoch 23600, Loss: 0.2618, Validation Loss: 982.0173\n",
      "Epoch 23700, Loss: 0.2642, Validation Loss: 982.1331\n",
      "Epoch 23800, Loss: 0.2622, Validation Loss: 982.2040\n",
      "Epoch 23900, Loss: 0.2618, Validation Loss: 981.8155\n",
      "Epoch 24000, Loss: 0.2644, Validation Loss: 981.8329\n",
      "Epoch 24100, Loss: 0.2616, Validation Loss: 981.7396\n",
      "Epoch 24200, Loss: 0.2622, Validation Loss: 981.7195\n",
      "Epoch 24300, Loss: 0.2639, Validation Loss: 981.1168\n",
      "Epoch 24400, Loss: 0.2624, Validation Loss: 981.7009\n",
      "Epoch 24500, Loss: 0.2629, Validation Loss: 981.3326\n",
      "Epoch 24600, Loss: 0.2621, Validation Loss: 981.6063\n",
      "Epoch 24700, Loss: 0.2622, Validation Loss: 981.7144\n",
      "Epoch 24800, Loss: 0.2635, Validation Loss: 981.6325\n",
      "Epoch 24900, Loss: 0.2632, Validation Loss: 981.2995\n",
      "Epoch 25000, Loss: 0.2606, Validation Loss: 981.3304\n",
      "Epoch 25100, Loss: 0.2640, Validation Loss: 981.1371\n",
      "Epoch 25200, Loss: 0.2624, Validation Loss: 981.2904\n",
      "Epoch 25300, Loss: 0.2622, Validation Loss: 981.1202\n",
      "Epoch 25400, Loss: 0.2639, Validation Loss: 981.0986\n",
      "Epoch 25500, Loss: 0.2627, Validation Loss: 980.9664\n",
      "Epoch 25600, Loss: 0.2632, Validation Loss: 981.0618\n",
      "Epoch 25700, Loss: 0.2608, Validation Loss: 980.9534\n",
      "Epoch 25800, Loss: 0.2582, Validation Loss: 980.8093\n",
      "Epoch 25900, Loss: 0.2641, Validation Loss: 980.6851\n",
      "Epoch 26000, Loss: 0.2623, Validation Loss: 980.7095\n",
      "Epoch 26100, Loss: 0.2604, Validation Loss: 981.0623\n",
      "Epoch 26200, Loss: 0.2657, Validation Loss: 981.0422\n",
      "Epoch 26300, Loss: 0.2651, Validation Loss: 981.2041\n",
      "Epoch 26400, Loss: 0.2613, Validation Loss: 981.4993\n",
      "Epoch 26500, Loss: 0.2631, Validation Loss: 981.1892\n",
      "Epoch 26600, Loss: 0.2644, Validation Loss: 981.2025\n",
      "Epoch 26700, Loss: 0.2613, Validation Loss: 981.6407\n",
      "Epoch 26800, Loss: 0.2613, Validation Loss: 981.5695\n",
      "Epoch 26900, Loss: 0.2636, Validation Loss: 980.9285\n",
      "Epoch 27000, Loss: 0.2614, Validation Loss: 981.1439\n",
      "Epoch 27100, Loss: 0.2619, Validation Loss: 980.7862\n",
      "Epoch 27200, Loss: 0.2607, Validation Loss: 980.8627\n",
      "Epoch 27300, Loss: 0.2599, Validation Loss: 980.5158\n",
      "Epoch 27400, Loss: 0.2626, Validation Loss: 980.5540\n",
      "Epoch 27500, Loss: 0.2613, Validation Loss: 980.7145\n",
      "Epoch 27600, Loss: 0.2586, Validation Loss: 980.5746\n",
      "Epoch 27700, Loss: 0.2651, Validation Loss: 980.3127\n",
      "Epoch 27800, Loss: 0.2618, Validation Loss: 980.4426\n",
      "Epoch 27900, Loss: 0.2613, Validation Loss: 980.2497\n",
      "Epoch 28000, Loss: 0.2591, Validation Loss: 980.1418\n",
      "Epoch 28100, Loss: 0.2606, Validation Loss: 980.0460\n",
      "Epoch 28200, Loss: 0.2619, Validation Loss: 980.1397\n",
      "Epoch 28300, Loss: 0.2622, Validation Loss: 980.0726\n",
      "Epoch 28400, Loss: 0.2631, Validation Loss: 980.1404\n",
      "Epoch 28500, Loss: 0.2648, Validation Loss: 980.5654\n",
      "Epoch 28600, Loss: 0.2651, Validation Loss: 980.3160\n",
      "Epoch 28700, Loss: 0.2634, Validation Loss: 980.4738\n",
      "Epoch 28800, Loss: 0.2624, Validation Loss: 980.4677\n",
      "Epoch 28900, Loss: 0.2639, Validation Loss: 980.4996\n",
      "Epoch 29000, Loss: 0.2621, Validation Loss: 980.6417\n",
      "Epoch 29100, Loss: 0.2604, Validation Loss: 980.7219\n",
      "Epoch 29200, Loss: 0.2618, Validation Loss: 980.4329\n",
      "Epoch 29300, Loss: 0.2644, Validation Loss: 980.5310\n",
      "Epoch 29400, Loss: 0.2603, Validation Loss: 980.5413\n",
      "Epoch 29500, Loss: 0.2591, Validation Loss: 980.6131\n",
      "Epoch 29600, Loss: 0.2620, Validation Loss: 980.8991\n",
      "Epoch 29700, Loss: 0.2628, Validation Loss: 980.6410\n",
      "Epoch 29800, Loss: 0.2622, Validation Loss: 980.6895\n",
      "Epoch 29900, Loss: 0.2595, Validation Loss: 980.6400\n",
      "Epoch 30000, Loss: 0.2607, Validation Loss: 980.7082\n",
      "Epoch 30100, Loss: 0.2632, Validation Loss: 980.7342\n",
      "Epoch 30200, Loss: 0.2621, Validation Loss: 980.6536\n",
      "Epoch 30300, Loss: 0.2601, Validation Loss: 980.9639\n",
      "Epoch 30400, Loss: 0.2620, Validation Loss: 980.8427\n",
      "Epoch 30500, Loss: 0.2641, Validation Loss: 980.6891\n",
      "Epoch 30600, Loss: 0.2607, Validation Loss: 980.8768\n",
      "Epoch 30700, Loss: 0.2633, Validation Loss: 981.0966\n",
      "Epoch 30800, Loss: 0.2633, Validation Loss: 980.8178\n",
      "Epoch 30900, Loss: 0.2648, Validation Loss: 980.8591\n",
      "Epoch 31000, Loss: 0.2632, Validation Loss: 980.9102\n",
      "Epoch 31100, Loss: 0.2642, Validation Loss: 980.6982\n",
      "Epoch 31200, Loss: 0.2612, Validation Loss: 980.7717\n",
      "Epoch 31300, Loss: 0.2601, Validation Loss: 980.8212\n",
      "Epoch 31400, Loss: 0.2612, Validation Loss: 980.7698\n",
      "Epoch 31500, Loss: 0.2609, Validation Loss: 980.8113\n",
      "Epoch 31600, Loss: 0.2647, Validation Loss: 981.0925\n",
      "Epoch 31700, Loss: 0.2603, Validation Loss: 981.1644\n",
      "Epoch 31800, Loss: 0.2641, Validation Loss: 980.7134\n",
      "Epoch 31900, Loss: 0.2631, Validation Loss: 980.9109\n",
      "Epoch 32000, Loss: 0.2598, Validation Loss: 981.2047\n",
      "Epoch 32100, Loss: 0.2635, Validation Loss: 980.9838\n",
      "Epoch 32200, Loss: 0.2604, Validation Loss: 981.1456\n",
      "Epoch 32300, Loss: 0.2630, Validation Loss: 981.0709\n",
      "Epoch 32400, Loss: 0.2618, Validation Loss: 980.9732\n",
      "Epoch 32500, Loss: 0.2590, Validation Loss: 980.9536\n",
      "Epoch 32600, Loss: 0.2610, Validation Loss: 980.6643\n",
      "Epoch 32700, Loss: 0.2592, Validation Loss: 980.9689\n",
      "Epoch 32800, Loss: 0.2630, Validation Loss: 981.0584\n",
      "Epoch 32900, Loss: 0.2632, Validation Loss: 981.0557\n",
      "Epoch 33000, Loss: 0.2642, Validation Loss: 981.1399\n",
      "Epoch 33100, Loss: 0.2648, Validation Loss: 981.4141\n",
      "Epoch 33200, Loss: 0.2629, Validation Loss: 981.2263\n",
      "Epoch 33300, Loss: 0.2615, Validation Loss: 981.4649\n",
      "Epoch 33400, Loss: 0.2612, Validation Loss: 980.7141\n",
      "Epoch 33500, Loss: 0.2613, Validation Loss: 980.9371\n",
      "Epoch 33600, Loss: 0.2627, Validation Loss: 980.9827\n",
      "Epoch 33700, Loss: 0.2616, Validation Loss: 980.7016\n",
      "Epoch 33800, Loss: 0.2641, Validation Loss: 980.6567\n",
      "Epoch 33900, Loss: 0.2611, Validation Loss: 980.7527\n",
      "Epoch 34000, Loss: 0.2611, Validation Loss: 980.4933\n",
      "Epoch 34100, Loss: 0.2601, Validation Loss: 980.5567\n",
      "Epoch 34200, Loss: 0.2601, Validation Loss: 980.5992\n",
      "Epoch 34300, Loss: 0.2613, Validation Loss: 980.5620\n",
      "Epoch 34400, Loss: 0.2632, Validation Loss: 980.4638\n",
      "Epoch 34500, Loss: 0.2629, Validation Loss: 980.4046\n",
      "Epoch 34600, Loss: 0.2621, Validation Loss: 980.6499\n",
      "Epoch 34700, Loss: 0.2613, Validation Loss: 980.7808\n",
      "Epoch 34800, Loss: 0.2639, Validation Loss: 980.4816\n",
      "Epoch 34900, Loss: 0.2603, Validation Loss: 980.2809\n",
      "Epoch 35000, Loss: 0.2625, Validation Loss: 980.3180\n",
      "Epoch 35100, Loss: 0.2624, Validation Loss: 980.2390\n",
      "Epoch 35200, Loss: 0.2615, Validation Loss: 980.4812\n",
      "Epoch 35300, Loss: 0.2640, Validation Loss: 980.2385\n",
      "Epoch 35400, Loss: 0.2610, Validation Loss: 980.1409\n",
      "Epoch 35500, Loss: 0.2627, Validation Loss: 980.1804\n",
      "Epoch 35600, Loss: 0.2635, Validation Loss: 980.3598\n",
      "Epoch 35700, Loss: 0.2593, Validation Loss: 980.2066\n",
      "Epoch 35800, Loss: 0.2619, Validation Loss: 980.3033\n",
      "Epoch 35900, Loss: 0.2625, Validation Loss: 980.1530\n",
      "Epoch 36000, Loss: 0.2614, Validation Loss: 980.1011\n",
      "Epoch 36100, Loss: 0.2596, Validation Loss: 979.9656\n",
      "Epoch 36200, Loss: 0.2623, Validation Loss: 979.4500\n",
      "Epoch 36300, Loss: 0.2606, Validation Loss: 979.8422\n",
      "Epoch 36400, Loss: 0.2635, Validation Loss: 979.6151\n",
      "Epoch 36500, Loss: 0.2611, Validation Loss: 979.7953\n",
      "Epoch 36600, Loss: 0.2631, Validation Loss: 979.4150\n",
      "Epoch 36700, Loss: 0.2626, Validation Loss: 979.8022\n",
      "Epoch 36800, Loss: 0.2608, Validation Loss: 979.3409\n",
      "Epoch 36900, Loss: 0.2635, Validation Loss: 979.4772\n",
      "Epoch 37000, Loss: 0.2618, Validation Loss: 979.1943\n",
      "Epoch 37100, Loss: 0.2615, Validation Loss: 979.1620\n",
      "Epoch 37200, Loss: 0.2587, Validation Loss: 979.0234\n",
      "Epoch 37300, Loss: 0.2630, Validation Loss: 978.8633\n",
      "Epoch 37400, Loss: 0.2594, Validation Loss: 979.0699\n",
      "Epoch 37500, Loss: 0.2622, Validation Loss: 978.9842\n",
      "Epoch 37600, Loss: 0.2601, Validation Loss: 979.0297\n",
      "Epoch 37700, Loss: 0.2615, Validation Loss: 979.0097\n",
      "Epoch 37800, Loss: 0.2616, Validation Loss: 978.7482\n",
      "Epoch 37900, Loss: 0.2583, Validation Loss: 978.6725\n",
      "Epoch 38000, Loss: 0.2608, Validation Loss: 978.6378\n",
      "Epoch 38100, Loss: 0.2629, Validation Loss: 978.2853\n",
      "Epoch 38200, Loss: 0.2622, Validation Loss: 978.4772\n",
      "Epoch 38300, Loss: 0.2609, Validation Loss: 978.7877\n",
      "Epoch 38400, Loss: 0.2600, Validation Loss: 978.6648\n",
      "Epoch 38500, Loss: 0.2587, Validation Loss: 978.4943\n",
      "Epoch 38600, Loss: 0.2623, Validation Loss: 978.5964\n",
      "Epoch 38700, Loss: 0.2629, Validation Loss: 978.5807\n",
      "Epoch 38800, Loss: 0.2623, Validation Loss: 978.7411\n",
      "Epoch 38900, Loss: 0.2635, Validation Loss: 978.6364\n",
      "Epoch 39000, Loss: 0.2628, Validation Loss: 978.8644\n",
      "Epoch 39100, Loss: 0.2592, Validation Loss: 978.1210\n",
      "Epoch 39200, Loss: 0.2633, Validation Loss: 977.9413\n",
      "Epoch 39300, Loss: 0.2619, Validation Loss: 977.2398\n",
      "Epoch 39400, Loss: 0.2612, Validation Loss: 976.7207\n",
      "Epoch 39500, Loss: 0.2620, Validation Loss: 976.4540\n",
      "Epoch 39600, Loss: 0.2625, Validation Loss: 975.6893\n",
      "Epoch 39700, Loss: 0.2618, Validation Loss: 975.1096\n",
      "Epoch 39800, Loss: 0.2602, Validation Loss: 974.8633\n",
      "Epoch 39900, Loss: 0.2618, Validation Loss: 974.5630\n",
      "Epoch 40000, Loss: 0.2635, Validation Loss: 974.6888\n",
      "Epoch 40100, Loss: 0.2588, Validation Loss: 974.0198\n",
      "Epoch 40200, Loss: 0.2628, Validation Loss: 973.5118\n",
      "Epoch 40300, Loss: 0.2614, Validation Loss: 973.2135\n",
      "Epoch 40400, Loss: 0.2623, Validation Loss: 972.9633\n",
      "Epoch 40500, Loss: 0.2609, Validation Loss: 972.1806\n",
      "Epoch 40600, Loss: 0.2620, Validation Loss: 972.0231\n",
      "Epoch 40700, Loss: 0.2608, Validation Loss: 971.3593\n",
      "Epoch 40800, Loss: 0.2614, Validation Loss: 971.3434\n",
      "Epoch 40900, Loss: 0.2606, Validation Loss: 971.2891\n",
      "Epoch 41000, Loss: 0.2604, Validation Loss: 970.4341\n",
      "Epoch 41100, Loss: 0.2589, Validation Loss: 970.4745\n",
      "Epoch 41200, Loss: 0.2647, Validation Loss: 969.9704\n",
      "Epoch 41300, Loss: 0.2634, Validation Loss: 969.6425\n",
      "Epoch 41400, Loss: 0.2623, Validation Loss: 969.6330\n",
      "Epoch 41500, Loss: 0.2648, Validation Loss: 969.4592\n",
      "Epoch 41600, Loss: 0.2608, Validation Loss: 969.4982\n",
      "Epoch 41700, Loss: 0.2611, Validation Loss: 968.8519\n",
      "Epoch 41800, Loss: 0.2609, Validation Loss: 968.7002\n",
      "Epoch 41900, Loss: 0.2621, Validation Loss: 968.5942\n",
      "Epoch 42000, Loss: 0.2625, Validation Loss: 968.3739\n",
      "Epoch 42100, Loss: 0.2631, Validation Loss: 968.1931\n",
      "Epoch 42200, Loss: 0.2641, Validation Loss: 967.9826\n",
      "Epoch 42300, Loss: 0.2597, Validation Loss: 967.8431\n",
      "Epoch 42400, Loss: 0.2611, Validation Loss: 967.0711\n",
      "Epoch 42500, Loss: 0.2620, Validation Loss: 966.8466\n",
      "Epoch 42600, Loss: 0.2613, Validation Loss: 966.7543\n",
      "Epoch 42700, Loss: 0.2619, Validation Loss: 966.4765\n",
      "Epoch 42800, Loss: 0.2650, Validation Loss: 966.5231\n",
      "Epoch 42900, Loss: 0.2597, Validation Loss: 966.0901\n",
      "Epoch 43000, Loss: 0.2634, Validation Loss: 966.2480\n",
      "Epoch 43100, Loss: 0.2607, Validation Loss: 966.1633\n",
      "Epoch 43200, Loss: 0.2647, Validation Loss: 965.5674\n",
      "Epoch 43300, Loss: 0.2562, Validation Loss: 965.5037\n",
      "Epoch 43400, Loss: 0.2618, Validation Loss: 965.3846\n",
      "Epoch 43500, Loss: 0.2636, Validation Loss: 965.3414\n",
      "Epoch 43600, Loss: 0.2639, Validation Loss: 964.9357\n",
      "Epoch 43700, Loss: 0.2600, Validation Loss: 964.9266\n",
      "Epoch 43800, Loss: 0.2605, Validation Loss: 964.5937\n",
      "Epoch 43900, Loss: 0.2629, Validation Loss: 964.6751\n",
      "Epoch 44000, Loss: 0.2615, Validation Loss: 964.6989\n",
      "Epoch 44100, Loss: 0.2591, Validation Loss: 964.7214\n",
      "Epoch 44200, Loss: 0.2611, Validation Loss: 964.4827\n",
      "Epoch 44300, Loss: 0.2649, Validation Loss: 964.3418\n",
      "Epoch 44400, Loss: 0.2587, Validation Loss: 964.2668\n",
      "Epoch 44500, Loss: 0.2628, Validation Loss: 964.6093\n",
      "Epoch 44600, Loss: 0.2598, Validation Loss: 964.3454\n",
      "Epoch 44700, Loss: 0.2603, Validation Loss: 964.5164\n",
      "Epoch 44800, Loss: 0.2615, Validation Loss: 964.4819\n",
      "Epoch 44900, Loss: 0.2602, Validation Loss: 964.3292\n",
      "Epoch 45000, Loss: 0.2610, Validation Loss: 964.1549\n",
      "Epoch 45100, Loss: 0.2605, Validation Loss: 964.6018\n",
      "Epoch 45200, Loss: 0.2620, Validation Loss: 964.0927\n",
      "Epoch 45300, Loss: 0.2610, Validation Loss: 964.2660\n",
      "Epoch 45400, Loss: 0.2598, Validation Loss: 964.3555\n",
      "Epoch 45500, Loss: 0.2593, Validation Loss: 964.3892\n",
      "Epoch 45600, Loss: 0.2631, Validation Loss: 964.1098\n",
      "Epoch 45700, Loss: 0.2594, Validation Loss: 964.4583\n",
      "Epoch 45800, Loss: 0.2604, Validation Loss: 964.5969\n",
      "Epoch 45900, Loss: 0.2584, Validation Loss: 964.0579\n",
      "Epoch 46000, Loss: 0.2598, Validation Loss: 964.1387\n",
      "Epoch 46100, Loss: 0.2624, Validation Loss: 963.9266\n",
      "Epoch 46200, Loss: 0.2589, Validation Loss: 963.7620\n",
      "Epoch 46300, Loss: 0.2596, Validation Loss: 964.2618\n",
      "Epoch 46400, Loss: 0.2608, Validation Loss: 964.2123\n",
      "Epoch 46500, Loss: 0.2586, Validation Loss: 964.3705\n",
      "Epoch 46600, Loss: 0.2581, Validation Loss: 964.0062\n",
      "Epoch 46700, Loss: 0.2626, Validation Loss: 964.3345\n",
      "Epoch 46800, Loss: 0.2650, Validation Loss: 963.7417\n",
      "Epoch 46900, Loss: 0.2615, Validation Loss: 963.7977\n",
      "Epoch 47000, Loss: 0.2626, Validation Loss: 963.7364\n",
      "Epoch 47100, Loss: 0.2577, Validation Loss: 963.7202\n",
      "Epoch 47200, Loss: 0.2593, Validation Loss: 963.6745\n",
      "Epoch 47300, Loss: 0.2623, Validation Loss: 963.6941\n",
      "Epoch 47400, Loss: 0.2591, Validation Loss: 963.7523\n",
      "Epoch 47500, Loss: 0.2615, Validation Loss: 963.6074\n",
      "Epoch 47600, Loss: 0.2617, Validation Loss: 963.4116\n",
      "Epoch 47700, Loss: 0.2616, Validation Loss: 963.6849\n",
      "Epoch 47800, Loss: 0.2632, Validation Loss: 963.8116\n",
      "Epoch 47900, Loss: 0.2599, Validation Loss: 963.4936\n",
      "Epoch 48000, Loss: 0.2612, Validation Loss: 963.5953\n",
      "Epoch 48100, Loss: 0.2608, Validation Loss: 963.4614\n",
      "Epoch 48200, Loss: 0.2598, Validation Loss: 963.8982\n",
      "Epoch 48300, Loss: 0.2626, Validation Loss: 963.6022\n",
      "Epoch 48400, Loss: 0.2610, Validation Loss: 963.6920\n",
      "Epoch 48500, Loss: 0.2610, Validation Loss: 963.6367\n",
      "Epoch 48600, Loss: 0.2607, Validation Loss: 963.5393\n",
      "Epoch 48700, Loss: 0.2636, Validation Loss: 963.7290\n",
      "Epoch 48800, Loss: 0.2625, Validation Loss: 963.2107\n",
      "Epoch 48900, Loss: 0.2590, Validation Loss: 963.3884\n",
      "Epoch 49000, Loss: 0.2606, Validation Loss: 963.2417\n",
      "Epoch 49100, Loss: 0.2645, Validation Loss: 963.3156\n",
      "Epoch 49200, Loss: 0.2610, Validation Loss: 963.5309\n",
      "Epoch 49300, Loss: 0.2595, Validation Loss: 963.4157\n",
      "Epoch 49400, Loss: 0.2590, Validation Loss: 963.1473\n",
      "Epoch 49500, Loss: 0.2598, Validation Loss: 963.0258\n",
      "Epoch 49600, Loss: 0.2638, Validation Loss: 963.1450\n",
      "Epoch 49700, Loss: 0.2617, Validation Loss: 963.0275\n",
      "Epoch 49800, Loss: 0.2594, Validation Loss: 963.5550\n",
      "Epoch 49900, Loss: 0.2612, Validation Loss: 963.2034\n",
      "Training finished\n",
      "INFO: Generating Linear Model\n",
      "Model Generated!\n"
     ]
    }
   ],
   "source": [
    "print(\"INFO: Training Network\")\n",
    "net = get_trained_network('../configs/nn_config.ini')\n",
    "print(\"INFO: Generating Linear Model\")\n",
    "model, ld_model = generate_nn_linear_models('../configs/nn_config.ini', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dash = 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sghmc_sampler = SGHMCsampler(model, 7500, ld_model.mean, 750, ld_model.mean, Minv=np.diag(np.full(d_dash, 1)), gamma=0.003, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:09<00:00, 10.80it/s]\n",
      "100%|██████████| 750/750 [01:09<00:00, 10.73it/s]\n",
      "100%|██████████| 750/750 [01:10<00:00, 10.63it/s]\n",
      "100%|██████████| 750/750 [01:10<00:00, 10.62it/s]\n",
      "100%|██████████| 750/750 [01:13<00:00, 10.20it/s]\n",
      "100%|██████████| 750/750 [01:12<00:00, 10.34it/s]\n",
      "100%|██████████| 750/750 [01:10<00:00, 10.61it/s]\n",
      "100%|██████████| 750/750 [01:10<00:00, 10.62it/s]\n",
      "100%|██████████| 750/750 [01:11<00:00, 10.52it/s]\n",
      "100%|██████████| 750/750 [01:10<00:00, 10.58it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "sghmc_samples = np.zeros((N, d_dash))\n",
    "for i in range(N):\n",
    "\tsghmc_samples[i] = sghmc_sampler.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_samples \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultivariate_normal(np\u001b[39m.\u001b[39mzeros(d_dash), ld_model\u001b[39m.\u001b[39mHinv, size\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m)\n\u001b[1;32m      2\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "test_samples = np.random.multivariate_normal(np.zeros(d_dash), ld_model.Hinv, size=500)\n",
    "fig, ax = plt.subplots(3,3)\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        a = 1\n",
    "        b = 1\n",
    "        while a == b:    \n",
    "            a = np.random.randint(0, d_dash)\n",
    "            b = np.random.randint(0, d_dash)\n",
    "            if a != b: \n",
    "                ax[i][j].scatter(sghmc_samples[:,a], sghmc_samples[:,b], color='Black', marker='+', label=\"Least Squares Samples\")\n",
    "                ax[i][j].scatter(test_samples[:,a], test_samples[:,b], c='Grey', zorder=-1, label=\"Test Samples\")\n",
    "                ax[i][j].set_xlabel(\"x{}\".format(a))\n",
    "                ax[i][j].set_ylabel(\"x{}\".format(b))\n",
    "handles, labels = ax[1][2].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center')\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=1.1,\n",
    "                    top=0.85,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomsEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
